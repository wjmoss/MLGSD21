{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "spectral_clustering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYuaUt61Vkav"
      },
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import scipy.sparse as sp"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMPWBnY3Vka0"
      },
      "source": [
        "# Project 4: Spectral clustering users based on their preferences (50 pt)\n",
        "\n",
        "The goal of this task is to find groups of users with similar preferences using **Spectral clustering**. \n",
        "You are given a fragment of the Yelp social network, represented by an undirected weighted graph.\n",
        "Nodes in the graph represent users.\n",
        "If two users are connected by an edge of weight $w$, it means that they have both left positive reviews to the same $w$ restaurants.\n",
        "\n",
        "Additionally, you are given a matrix `F` that encodes user preferences to different categories of restaurants. If `F[i, c] = 1`, then user `i` likes restaurants in category `c`.\n",
        "\n",
        "You are allowed to use the imported functions (`eigsh`, `KMeans`, `normalize`).\n",
        "\n",
        "## General remarks\n",
        "Do not add or modify any code outside of the following comment blocks, or where otherwise explicitly stated.\n",
        "\n",
        "``` python\n",
        "##########################################################\n",
        "# YOUR CODE HERE\n",
        "...\n",
        "##########################################################\n",
        "```\n",
        "After you fill in all the missing code, restart the kernel and re-run all the cells in the notebook.\n",
        "\n",
        "The following things are **NOT** allowed:\n",
        "- Using additional `import` statements\n",
        "- Copying / reusing code from other sources (e.g. code by other students)\n",
        "\n",
        "If you plagiarise even for a single project task, you won't be eligible for the bonus this semester."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjLM7ctCVka0"
      },
      "source": [
        "## Load the data\n",
        "\n",
        "* `N` = number of users (nodes in the graph)\n",
        "* `C` = number of categories\n",
        "* The graph is stored as a _sparse adjacency matrix_ `A` (shape `[N, N]`).\n",
        "* User preferences are stored in a _feature matrix_ `F` (shape `[N, C]`). They will only be used for the final part of the assignment (Part 3)\n",
        "* Name of each category is provided in the list `categories` (length `[C]`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31BgsHBpVka1"
      },
      "source": [
        "A = sp.load_npz('A.npz')\n",
        "F = np.load('F.npy')\n",
        "categories = np.load('categories.npy', allow_pickle=True).tolist()"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUrxT805Vka1"
      },
      "source": [
        "assert A.shape[0] == F.shape[0]\n",
        "assert F.shape[1] == len(categories)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKZ50Z3zVka1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "153dcea9-5712-4339-df48-7d27fb246cca"
      },
      "source": [
        "print(f'The adjacency matrix is {\"symmetric\" if (A != A.T).sum() == 0 else \"asymmetric\"}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The adjacency matrix is symmetric\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd-CTvI9Vka2"
      },
      "source": [
        "# 1. Implementing spectral clustering (35 pt)\n",
        "## 1.1. Construct the graph Laplacian (10 pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co9xCO6wVka3"
      },
      "source": [
        "First, we need to construct the Laplacian for the given graph (*Do only use sparse operations, see [Scipy Sparse](https://docs.scipy.org/doc/scipy/reference/sparse.html)*). \n",
        "\n",
        "Given the **adjacency matrix** $A \\in \\mathbb{R}^{N \\times N},$ we define the **degree matrix** $D \\in \\mathbb{R}^{N \\times N}$ of an undirected graph as\n",
        "$$D_{ij} =  \\begin{cases}\\sum_{k=1}^N A_{ik} & if \\;\\; i = j\\\\ 0 & if \\;\\; i \\ne j\\end{cases}$$\n",
        "\n",
        "If our goal is to minimize the **ratio cut**, we will need to use the **unnormalized Laplacian**, defined as\n",
        "$$L_{unnorm} = D - A.$$\n",
        "\n",
        "If our goal is to minimze the **normalized cut**, we will need to use the **normalized Laplacian** (a.k.a. symmetrized Laplacian), defined as\n",
        "$$L_{sym} = I - D^{-1/2}AD^{-1/2}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EBtl01XW5We",
        "outputId": "9536367e-cfd6-4d2a-8a57-72dd0b067c32"
      },
      "source": [
        "row = np.array([1, 0, 1, 2, 2, 2])\n",
        "col = np.array([0, 1, 2, 0, 1, 2])\n",
        "data = np.array([2, 2, 3, 0, 3, 6])\n",
        "M=sp.csr_matrix((data, (row, col)), shape=(4, 4))\n",
        "#csr_matrix((data, (row, col)), shape=(3, 3)).toarray()\n",
        "M.toarray()\n",
        "M.shape[1]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNJZEZc9YCe2",
        "outputId": "572717ad-d18c-4d72-c7c6-406684e148c3"
      },
      "source": [
        "(M @ M).toarray()\n",
        "np.sum(M, axis=1)\n",
        "np.array(range(3))\n",
        "np.sqrt(np.array(range(3)))\n",
        "t=np.array(range(3)).reshape(1,-1)\n",
        "t.T\n",
        "t * np.array([[1,2,3],[1,2,3],[1,2,3]])\n",
        "(M * M).toarray()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4,  0,  6,  0],\n",
              "       [ 0, 13, 18,  0],\n",
              "       [ 6, 18, 45,  0],\n",
              "       [ 0,  0,  0,  0]], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smCytk8qmUic",
        "outputId": "fd300171-c503-4258-d23d-43b5135fccbd"
      },
      "source": [
        "M.toarray()\n",
        "construct_laplacian(M, norm_laplacian=False).asfptype().toarray()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2., -2.,  0.,  0.],\n",
              "       [-2.,  5., -3.,  0.],\n",
              "       [ 0., -3.,  3.,  0.],\n",
              "       [ 0.,  0.,  0.,  0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3VW8RcRauxS",
        "outputId": "1f760d24-05d8-4368-aff4-c000a26fa809"
      },
      "source": [
        "K=construct_laplacian(M, norm_laplacian=False).asfptype().toarray()\n",
        "t=eigsh(K,k=3,which='SM')\n",
        "t[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: RuntimeWarning: divide by zero encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-4.13228385e-01, -4.03206691e-01, -7.65055324e-01],\n",
              "       [-4.13228385e-01, -4.03206691e-01,  1.35509923e-01],\n",
              "       [-4.13228385e-01, -4.03206691e-01,  6.29545401e-01],\n",
              "       [-6.98374474e-01,  7.15732557e-01,  1.14459432e-16]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tVS6bGQbor6",
        "outputId": "6be54c47-4c20-44e1-e682-70ca8cdf87f7"
      },
      "source": [
        "A=M\n",
        "N = A.shape[0]\n",
        "diag = np.sum(A, axis=1).reshape(-1)\n",
        "inv = np.sqrt(1 / diag)\n",
        "row = np.array(range(N))\n",
        "col = np.array(range(N))\n",
        "sp.csr_matrix((row, (row, col)), shape=(N, N)).toarray()\n",
        "#np.asarray(diag).reshape(-1)\n",
        "diag"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[2, 5, 9]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UGwbFp6Vka3"
      },
      "source": [
        "def construct_laplacian(A: sp.csr_matrix, norm_laplacian: bool) -> sp.csr_matrix:\n",
        "    \"\"\"Construct Laplacian of a graph.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    A : scipy.sparse.csr_matrix, shape [N, N]\n",
        "        Adjacency matrix of the graph.\n",
        "    norm_laplacian : bool\n",
        "        Whether to construct the normalized graph Laplacian or not.\n",
        "        If True, construct the normalized (symmetrized) Laplacian, L = I - D^{-1/2} A D^{-1/2}.\n",
        "        If False, construct the unnormalized Laplacian, L = D - A.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    L : scipy.sparse.csr_matrix, shape [N, N]\n",
        "        Laplacian of the graph.\n",
        "        \n",
        "    \"\"\"\n",
        "    ##########################################################\n",
        "    # YOUR CODE HERE\n",
        "    N = A.shape[0]\n",
        "    diag = np.asarray(np.sum(A, axis=1)).reshape(-1)\n",
        "    #inv = np.sqrt(1 / diag)\n",
        "    inv = [1/x if x!= 0 else 0 for x in diag]\n",
        "    L = sp.csr_matrix((diag, (np.array(range(N)), np.array(range(N)))), shape=(N, N)) - A\n",
        "    if norm_laplacian:\n",
        "      tmp = sp.csr_matrix((inv, (np.array(range(N)), np.array(range(N)))), shape=(N, N))\n",
        "      L = tmp * L * tmp\n",
        "    ##########################################################\n",
        "    return L"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bk4MQUI0Vka4"
      },
      "source": [
        "## 1.2. Spectral embedding (10 pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJf3YTh-Vka4"
      },
      "source": [
        "Now, we have to compute the spectral embedding for the given graph.\n",
        "\n",
        "In order to partition the graph into $k$ clusters, such that the desired cut (ratio or normalized) is minimized, we need to consider the $k$ eigenvectors corresponding to the $k$ smallest eigenvalues of the graph Laplacian.\n",
        "\n",
        "Since the Laplacian matrix is sparse and symmetric, we can use the function `eigsh` from the `scipy.sparse.linalg` package in order to find eigendecomposition of $L$ (`eig` - eigendecomposition, `s` - sparse, `h`- Hermitian).\n",
        "The function `eigsh` directly allows you to find the smallest / largest eigenvalues by specifying the `k` and `which` parameters. \n",
        "\n",
        "Keep in mind that the Laplacian matrix is always positive semi-definite when picking the appropriate value for the `which` parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebwdXoJRVka4"
      },
      "source": [
        "from scipy.sparse.linalg import eigsh"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "cLks-eUDVka5",
        "outputId": "11422e70-249b-4e23-cfd3-3ffe24c1d040"
      },
      "source": [
        "help(eigsh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function eigsh in module scipy.sparse.linalg.eigen.arpack.arpack:\n",
            "\n",
            "eigsh(A, k=6, M=None, sigma=None, which='LM', v0=None, ncv=None, maxiter=None, tol=0, return_eigenvectors=True, Minv=None, OPinv=None, mode='normal')\n",
            "    Find k eigenvalues and eigenvectors of the real symmetric square matrix\n",
            "    or complex hermitian matrix A.\n",
            "    \n",
            "    Solves ``A * x[i] = w[i] * x[i]``, the standard eigenvalue problem for\n",
            "    w[i] eigenvalues with corresponding eigenvectors x[i].\n",
            "    \n",
            "    If M is specified, solves ``A * x[i] = w[i] * M * x[i]``, the\n",
            "    generalized eigenvalue problem for w[i] eigenvalues\n",
            "    with corresponding eigenvectors x[i].\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    A : ndarray, sparse matrix or LinearOperator\n",
            "        A square operator representing the operation ``A * x``, where ``A`` is\n",
            "        real symmetric or complex hermitian. For buckling mode (see below)\n",
            "        ``A`` must additionally be positive-definite.\n",
            "    k : int, optional\n",
            "        The number of eigenvalues and eigenvectors desired.\n",
            "        `k` must be smaller than N. It is not possible to compute all\n",
            "        eigenvectors of a matrix.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    w : array\n",
            "        Array of k eigenvalues.\n",
            "    v : array\n",
            "        An array representing the `k` eigenvectors.  The column ``v[:, i]`` is\n",
            "        the eigenvector corresponding to the eigenvalue ``w[i]``.\n",
            "    \n",
            "    Other Parameters\n",
            "    ----------------\n",
            "    M : An N x N matrix, array, sparse matrix, or linear operator representing\n",
            "        the operation ``M @ x`` for the generalized eigenvalue problem\n",
            "    \n",
            "            A @ x = w * M @ x.\n",
            "    \n",
            "        M must represent a real, symmetric matrix if A is real, and must\n",
            "        represent a complex, hermitian matrix if A is complex. For best\n",
            "        results, the data type of M should be the same as that of A.\n",
            "        Additionally:\n",
            "    \n",
            "            If sigma is None, M is symmetric positive definite.\n",
            "    \n",
            "            If sigma is specified, M is symmetric positive semi-definite.\n",
            "    \n",
            "            In buckling mode, M is symmetric indefinite.\n",
            "    \n",
            "        If sigma is None, eigsh requires an operator to compute the solution\n",
            "        of the linear equation ``M @ x = b``. This is done internally via a\n",
            "        (sparse) LU decomposition for an explicit matrix M, or via an\n",
            "        iterative solver for a general linear operator.  Alternatively,\n",
            "        the user can supply the matrix or operator Minv, which gives\n",
            "        ``x = Minv @ b = M^-1 @ b``.\n",
            "    sigma : real\n",
            "        Find eigenvalues near sigma using shift-invert mode.  This requires\n",
            "        an operator to compute the solution of the linear system\n",
            "        ``[A - sigma * M] x = b``, where M is the identity matrix if\n",
            "        unspecified.  This is computed internally via a (sparse) LU\n",
            "        decomposition for explicit matrices A & M, or via an iterative\n",
            "        solver if either A or M is a general linear operator.\n",
            "        Alternatively, the user can supply the matrix or operator OPinv,\n",
            "        which gives ``x = OPinv @ b = [A - sigma * M]^-1 @ b``.\n",
            "        Note that when sigma is specified, the keyword 'which' refers to\n",
            "        the shifted eigenvalues ``w'[i]`` where:\n",
            "    \n",
            "            if mode == 'normal', ``w'[i] = 1 / (w[i] - sigma)``.\n",
            "    \n",
            "            if mode == 'cayley', ``w'[i] = (w[i] + sigma) / (w[i] - sigma)``.\n",
            "    \n",
            "            if mode == 'buckling', ``w'[i] = w[i] / (w[i] - sigma)``.\n",
            "    \n",
            "        (see further discussion in 'mode' below)\n",
            "    v0 : ndarray, optional\n",
            "        Starting vector for iteration.\n",
            "        Default: random\n",
            "    ncv : int, optional\n",
            "        The number of Lanczos vectors generated ncv must be greater than k and\n",
            "        smaller than n; it is recommended that ``ncv > 2*k``.\n",
            "        Default: ``min(n, max(2*k + 1, 20))``\n",
            "    which : str ['LM' | 'SM' | 'LA' | 'SA' | 'BE']\n",
            "        If A is a complex hermitian matrix, 'BE' is invalid.\n",
            "        Which `k` eigenvectors and eigenvalues to find:\n",
            "    \n",
            "            'LM' : Largest (in magnitude) eigenvalues.\n",
            "    \n",
            "            'SM' : Smallest (in magnitude) eigenvalues.\n",
            "    \n",
            "            'LA' : Largest (algebraic) eigenvalues.\n",
            "    \n",
            "            'SA' : Smallest (algebraic) eigenvalues.\n",
            "    \n",
            "            'BE' : Half (k/2) from each end of the spectrum.\n",
            "    \n",
            "        When k is odd, return one more (k/2+1) from the high end.\n",
            "        When sigma != None, 'which' refers to the shifted eigenvalues ``w'[i]``\n",
            "        (see discussion in 'sigma', above).  ARPACK is generally better\n",
            "        at finding large values than small values.  If small eigenvalues are\n",
            "        desired, consider using shift-invert mode for better performance.\n",
            "    maxiter : int, optional\n",
            "        Maximum number of Arnoldi update iterations allowed.\n",
            "        Default: ``n*10``\n",
            "    tol : float\n",
            "        Relative accuracy for eigenvalues (stopping criterion).\n",
            "        The default value of 0 implies machine precision.\n",
            "    Minv : N x N matrix, array, sparse matrix, or LinearOperator\n",
            "        See notes in M, above.\n",
            "    OPinv : N x N matrix, array, sparse matrix, or LinearOperator\n",
            "        See notes in sigma, above.\n",
            "    return_eigenvectors : bool\n",
            "        Return eigenvectors (True) in addition to eigenvalues.\n",
            "        This value determines the order in which eigenvalues are sorted.\n",
            "        The sort order is also dependent on the `which` variable.\n",
            "    \n",
            "            For which = 'LM' or 'SA':\n",
            "                If `return_eigenvectors` is True, eigenvalues are sorted by\n",
            "                algebraic value.\n",
            "    \n",
            "                If `return_eigenvectors` is False, eigenvalues are sorted by\n",
            "                absolute value.\n",
            "    \n",
            "            For which = 'BE' or 'LA':\n",
            "                eigenvalues are always sorted by algebraic value.\n",
            "    \n",
            "            For which = 'SM':\n",
            "                If `return_eigenvectors` is True, eigenvalues are sorted by\n",
            "                algebraic value.\n",
            "    \n",
            "                If `return_eigenvectors` is False, eigenvalues are sorted by\n",
            "                decreasing absolute value.\n",
            "    \n",
            "    mode : string ['normal' | 'buckling' | 'cayley']\n",
            "        Specify strategy to use for shift-invert mode.  This argument applies\n",
            "        only for real-valued A and sigma != None.  For shift-invert mode,\n",
            "        ARPACK internally solves the eigenvalue problem\n",
            "        ``OP * x'[i] = w'[i] * B * x'[i]``\n",
            "        and transforms the resulting Ritz vectors x'[i] and Ritz values w'[i]\n",
            "        into the desired eigenvectors and eigenvalues of the problem\n",
            "        ``A * x[i] = w[i] * M * x[i]``.\n",
            "        The modes are as follows:\n",
            "    \n",
            "            'normal' :\n",
            "                OP = [A - sigma * M]^-1 @ M,\n",
            "                B = M,\n",
            "                w'[i] = 1 / (w[i] - sigma)\n",
            "    \n",
            "            'buckling' :\n",
            "                OP = [A - sigma * M]^-1 @ A,\n",
            "                B = A,\n",
            "                w'[i] = w[i] / (w[i] - sigma)\n",
            "    \n",
            "            'cayley' :\n",
            "                OP = [A - sigma * M]^-1 @ [A + sigma * M],\n",
            "                B = M,\n",
            "                w'[i] = (w[i] + sigma) / (w[i] - sigma)\n",
            "    \n",
            "        The choice of mode will affect which eigenvalues are selected by\n",
            "        the keyword 'which', and can also impact the stability of\n",
            "        convergence (see [2] for a discussion).\n",
            "    \n",
            "    Raises\n",
            "    ------\n",
            "    ArpackNoConvergence\n",
            "        When the requested convergence is not obtained.\n",
            "    \n",
            "        The currently converged eigenvalues and eigenvectors can be found\n",
            "        as ``eigenvalues`` and ``eigenvectors`` attributes of the exception\n",
            "        object.\n",
            "    \n",
            "    See Also\n",
            "    --------\n",
            "    eigs : eigenvalues and eigenvectors for a general (nonsymmetric) matrix A\n",
            "    svds : singular value decomposition for a matrix A\n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    This function is a wrapper to the ARPACK [1]_ SSEUPD and DSEUPD\n",
            "    functions which use the Implicitly Restarted Lanczos Method to\n",
            "    find the eigenvalues and eigenvectors [2]_.\n",
            "    \n",
            "    References\n",
            "    ----------\n",
            "    .. [1] ARPACK Software, http://www.caam.rice.edu/software/ARPACK/\n",
            "    .. [2] R. B. Lehoucq, D. C. Sorensen, and C. Yang,  ARPACK USERS GUIDE:\n",
            "       Solution of Large Scale Eigenvalue Problems by Implicitly Restarted\n",
            "       Arnoldi Methods. SIAM, Philadelphia, PA, 1998.\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    >>> from scipy.sparse.linalg import eigsh\n",
            "    >>> identity = np.eye(13)\n",
            "    >>> eigenvalues, eigenvectors = eigsh(identity, k=6)\n",
            "    >>> eigenvalues\n",
            "    array([1., 1., 1., 1., 1., 1.])\n",
            "    >>> eigenvectors.shape\n",
            "    (13, 6)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuygXWTxVka5"
      },
      "source": [
        "def spectral_embedding(A: sp.csr_matrix, num_clusters: int, norm_laplacian: bool) -> np.array:\n",
        "    \"\"\"Compute spectral embedding of nodes in the given graph.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    A : scipy.sparse.csr_matrix, shape [N, N]\n",
        "        Adjacency matrix of the graph.\n",
        "    num_clusters : int\n",
        "        Number of clusters to detect in the data.\n",
        "    norm_laplacian : bool, default False\n",
        "        Whether to use the normalized graph Laplacian or not.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    embedding : np.array, shape [N, num_clusters]\n",
        "        Spectral embedding for the given graph.\n",
        "        Each row represents the spectral embedding of a given node.\n",
        "    \n",
        "    \"\"\"\n",
        "    if (A != A.T).sum() != 0:\n",
        "        raise ValueError(\"Spectral embedding doesn't work if the adjacency matrix is not symmetric.\")\n",
        "    if num_clusters < 2:\n",
        "        raise ValueError(\"The clustering requires at least two clusters.\")\n",
        "    if num_clusters > A.shape[0]:\n",
        "        raise ValueError(f\"We can have at most {A.shape[0]} clusters (number of nodes).\")\n",
        "    ##########################################################\n",
        "    # YOUR CODE HERE\n",
        "    L = construct_laplacian(A, norm_laplacian=norm_laplacian).asfptype().toarray()\n",
        "    eigenvalues, eigenvectors = eigsh(L, k=num_clusters)\n",
        "    ##########################################################\n",
        "    return eigenvectors"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJJ3sJ1eVka6"
      },
      "source": [
        "## 1.3. Determine the clusters based on the spectral embedding (15 pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP0mPA_uVka6"
      },
      "source": [
        "You should use the K-means algorithm for assigning nodes to clusters, once the spectral embedding is computed.\n",
        "\n",
        "One thing you should keep in mind, is that when using the **normalized Laplacian**, the rows of the embedding matrix **have to** be normalized to have unit $L_2$ norm. The justification of this approach is not trivial. If you are interested, the paper \"A tutorial on spectral clustering\" by Ulrike von Luxburg. Section 7 covers a justification involving Perturbation Theory. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjcwL7uNvcQJ",
        "outputId": "550134f4-b688-4d97-b898-dd04594ff31e"
      },
      "source": [
        "X = np.array([[1, 2], [1, 4], [1, 0],\n",
        "...               [10, 2], [10, 4], [10, 0]])\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  2],\n",
              "       [ 1,  4],\n",
              "       [ 1,  0],\n",
              "       [10,  2],\n",
              "       [10,  4],\n",
              "       [10,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsDG-iXdVka6"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import normalize"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNQFqwlsVka7"
      },
      "source": [
        "def spectral_clustering(A: sp.csr_matrix, num_clusters: int, norm_laplacian: bool, seed: int = 42) -> np.array:\n",
        "    \"\"\"Perform spectral clustering on the given graph.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    A : scipy.sparse.csr_matrix, shape [N, N]\n",
        "        Adjacency matrix of the graph.\n",
        "    num_clusters : int\n",
        "        Number of clusters to detect in the data.\n",
        "    norm_laplacian : bool, default False\n",
        "        Whether to use the normalized graph Laplacian or not.\n",
        "    seed : int, default 42\n",
        "        Random seed to use for the `KMeans` clustering.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    z_pred : np.array, shape [N]\n",
        "        Predicted cluster indicators for each node.\n",
        "        \n",
        "    \"\"\"\n",
        "    model = KMeans(num_clusters, random_state=seed)\n",
        "    ##########################################################\n",
        "    # YOUR CODE HERE\n",
        "    L = construct_laplacian(A, norm_laplacian=norm_laplacian).asfptype().toarray()\n",
        "    eigenvalues, eigenvectors = eigsh(L, k=num_clusters)\n",
        "    if norm_laplacian:\n",
        "      eigenvectors = normalize(eigenvectors, norm='l2')\n",
        "    kmeans = model.fit(eigenvectors)\n",
        "    z_pred = kmeans.labels_\n",
        "    ##########################################################\n",
        "    return z_pred"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwD9QrbQVka7"
      },
      "source": [
        "# 2. Quantitatively evaluate the results (10 pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5v5uT3KVka7"
      },
      "source": [
        "def labels_to_list_of_clusters(z: np.array) -> List[List[int]]:\n",
        "    \"\"\"Convert predicted label vector to a list of clusters in the graph.\n",
        "    This function is already implemented, nothing to do here.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    z : np.array, shape [N]\n",
        "        Predicted labels.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    list_of_clusters : list of lists\n",
        "        Each list contains ids of nodes that belong to the same cluster.\n",
        "        Each node may appear in one and only one partition.\n",
        "    \n",
        "    Examples\n",
        "    --------\n",
        "    >>> z = np.array([0, 0, 1, 1, 0])\n",
        "    >>> labels_to_list_of_clusters(z)\n",
        "    [[0, 1, 4], [2, 3]]\n",
        "    \n",
        "    \"\"\"\n",
        "    return [np.where(z == c)[0] for c in np.unique(z)]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWa1KEOCVka7"
      },
      "source": [
        "## 2.1. Compute ratio cut (5 pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sJPNtkOVka7"
      },
      "source": [
        "Your task is to implement functions for computing the **ratio cut** and **normalized cut** for a given partition.\n",
        "\n",
        "Ratio cut and normalized cut are defined on the slide 14 of the lecture slides.\n",
        "\n",
        "\n",
        "The function `labels_to_list_of_clusters` can be helpful here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA6XFbxT7MMw",
        "outputId": "26e57342-6e48-45a0-d692-6cf13839eb3f"
      },
      "source": [
        "x=[[0, 1, 4], [2, 3]]\n",
        "len(x)\n",
        "x[0]\n",
        "A.toarray()\n",
        "np.sum(A[[1,2],])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a89di3ngVka8"
      },
      "source": [
        "def compute_ratio_cut(A: sp.csr_matrix, z: np.array) -> float:\n",
        "    \"\"\"Compute the ratio cut for the given partition of the graph.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    A : scipy.sparse.csr_matrix, shape [N, N]\n",
        "        Adjacency matrix of the graph.\n",
        "    z : np.array, shape [N]\n",
        "        Cluster indicators for each node.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    ratio_cut : float\n",
        "        Value of the cut for the given partition of the graph.\n",
        "        \n",
        "    \"\"\"\n",
        "    \n",
        "    ##########################################################\n",
        "    # YOUR CODE HERE\n",
        "    partition = labels_to_list_of_clusters(z)\n",
        "    ratio_cut = 0\n",
        "    for item in partition:\n",
        "      ratio_cut += (np.sum(A[item, :]) - np.sum(A[item, item])) / len(item)\n",
        "    ##########################################################\n",
        "    return ratio_cut"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGbP3HtkVka8"
      },
      "source": [
        "## 2.2. Compute normalized cut (5 pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is8NlKrsVka8"
      },
      "source": [
        "**Important**: if a cluster only contains a single node, define its volume to be 1 to avoid division by zero errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoAOMeoUVka9"
      },
      "source": [
        "def compute_normalized_cut(A: sp.csr_matrix, z: np.array) -> float:\n",
        "    \"\"\"Compute the normalized cut for the given partition of the graph.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    A : scipy.sparse.csr_matrix, shape [N, N]\n",
        "        Adjacency matrix of the graph.\n",
        "    z : np.array, shape [N]\n",
        "        Cluster indicators for each node.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    norm_cut : float\n",
        "        Value of the normalized cut for the given partition of the graph.\n",
        "        \n",
        "    \"\"\"\n",
        "    \n",
        "    ##########################################################\n",
        "    # YOUR CODE HERE\n",
        "    partition = labels_to_list_of_clusters(z)\n",
        "    norm_cut = 0\n",
        "    for item in partition:\n",
        "      norm_cut += (np.sum(A[item, :]) - np.sum(A[item, item])) / max(np.sum(A[item, :]), 1)\n",
        "    ##########################################################\n",
        "    return norm_cut"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INiaWgeDVka9"
      },
      "source": [
        "Notice, how using the unnormalized Laplacian leads to a much better ratio cut, while the normalized Laplacian leads to better normalized cut."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oyjas0FeVka9"
      },
      "source": [
        "num_clusters = 6"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLRlng8nVka9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e546a821-be08-4d29-d336-ab54142a4e91"
      },
      "source": [
        "np.random.seed(12903)\n",
        "norm_laplacian = False\n",
        "z_unnorm = spectral_clustering(A, num_clusters, norm_laplacian)\n",
        "print('When using L_unnorm:')\n",
        "print(' ratio cut = {:.3f}'.format(compute_ratio_cut(A, z_unnorm)))\n",
        "print(' normalized cut = {:.3f}'.format(compute_normalized_cut(A, z_unnorm)))\n",
        "print(' sizes of partitions are: {}'.format([len(clust) for clust in labels_to_list_of_clusters(z_unnorm)]))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "When using L_unnorm:\n",
            " ratio cut = 58837.277\n",
            " normalized cut = 6.000\n",
            " sizes of partitions are: [3379, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-fy805wVka9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fe66f64-f200-4528-dc55-70440634afc4"
      },
      "source": [
        "np.random.seed(12323)\n",
        "norm_laplacian = True\n",
        "z_norm = spectral_clustering(A, num_clusters, norm_laplacian)\n",
        "print('When using L_norm:')\n",
        "print(' ratio cut = {:.3f}'.format(compute_ratio_cut(A, z_norm)))\n",
        "print(' normalized cut = {:.3f}'.format(compute_normalized_cut(A, z_norm)))\n",
        "print(' sizes of partitions are: {}'.format([len(clust) for clust in labels_to_list_of_clusters(z_norm)]))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "When using L_norm:\n",
            " ratio cut = 8228.430\n",
            " normalized cut = 6.000\n",
            " sizes of partitions are: [977, 153, 805, 310, 583, 556]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JX5bEBSUVka-"
      },
      "source": [
        "# 3. Visualize the results (5 pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkVWt4StVka-"
      },
      "source": [
        "In the final part of the assignment, your task is to print out the 5 most popular types of restaurants visited by the users in each cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxWMtj93Vka-"
      },
      "source": [
        "def print_top_categories_for_each_cluster(top_k: int, z: np.array, F: sp.csr_matrix, categories: List[str]):\n",
        "    \"\"\"Print the top-K categories among users in each cluster.\n",
        "    For each cluster, the function prints names of the top-K categories,\n",
        "    and number of users that like the respective category (separated by a comma).\n",
        "    The function doesn't return anything, just prints the output.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    top_k : int\n",
        "        Number of most popular categories to print for each cluster.\n",
        "    z : np.array, shape [N]\n",
        "        Cluster labels.\n",
        "    F : sp.csr_matrix, shape [N, C]\n",
        "        Matrix that tells preferences of each user to each category.\n",
        "        F[i, c] = 1 if user i gave at least one positive review to at least one restaurant in category c.\n",
        "    categories : list, shape [C]\n",
        "        Names of the categories.\n",
        "        \n",
        "    \"\"\"\n",
        "    ##########################################################\n",
        "    # YOUR CODE HERE\n",
        "    partition = labels_to_list_of_clusters(z)\n",
        "    for i, item in enumerate(partition):\n",
        "      rowsum = np.sum(F[item, :], axis=0)\n",
        "      indices = np.argsort(-rowsum)\n",
        "      print('Most popular categories in cluster ' + str(i))\n",
        "      for k in range(top_k):\n",
        "        print(' - ' + str(categories[indices[k]]) + ', ' + str(int(rowsum[indices[k]])))\n",
        "      print()\n",
        "    ##########################################################"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uTinChZERYI"
      },
      "source": [
        "partition = labels_to_list_of_clusters(z_norm)\n",
        "for i, item in enumerate(partition):\n",
        "  rowsum = np.sum(F[item, ], axis=0)\n",
        "  indices = np.argsort(-rowsum)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3MkFg7wEWww",
        "outputId": "0d5043a1-e344-4991-b0a4-052267adbaee"
      },
      "source": [
        "np.sum(np.array([[2,3],[4,5],[6,7]]), axis=0)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12, 15])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvyXQCfKByyd",
        "outputId": "3b58615e-298d-436d-fa1a-cc2e4953935e"
      },
      "source": [
        "print('Most popular categories in cluster ' + str(4))\n",
        "print(' - Seafood, ' + str(315))\n",
        "print(' ')\n",
        "print('Most popular categories in cluster ' + str(4))\n",
        "print(6)\n",
        "print()\n",
        "np.argsort(-np.array([3,2,4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most popular categories in cluster 4\n",
            " - Seafood, 315\n",
            " \n",
            "Most popular categories in cluster 4\n",
            "6\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMygFMV-Vka-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6c5224c-05a1-4f15-84c3-eb55b8f8b4ad"
      },
      "source": [
        "np.random.seed(23142)\n",
        "z_norm = spectral_clustering(A, num_clusters, True)\n",
        "r = print_top_categories_for_each_cluster(5, z_norm, F, categories)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most popular categories in cluster 0\n",
            " - Breakfast & Brunch, 816\n",
            " - Japanese, 751\n",
            " - Sandwiches, 689\n",
            " - Italian, 671\n",
            " - Coffee & Tea, 638\n",
            "\n",
            "Most popular categories in cluster 1\n",
            " - Breakfast & Brunch, 135\n",
            " - Italian, 131\n",
            " - Japanese, 118\n",
            " - Pizza, 115\n",
            " - Sandwiches, 115\n",
            "\n",
            "Most popular categories in cluster 2\n",
            " - Japanese, 652\n",
            " - Breakfast & Brunch, 636\n",
            " - Italian, 580\n",
            " - Asian Fusion, 527\n",
            " - Sandwiches, 520\n",
            "\n",
            "Most popular categories in cluster 3\n",
            " - Breakfast & Brunch, 268\n",
            " - Sandwiches, 253\n",
            " - Italian, 252\n",
            " - Japanese, 236\n",
            " - American (Traditional), 228\n",
            "\n",
            "Most popular categories in cluster 4\n",
            " - Breakfast & Brunch, 473\n",
            " - Japanese, 428\n",
            " - Italian, 416\n",
            " - Sandwiches, 407\n",
            " - Cafes, 353\n",
            "\n",
            "Most popular categories in cluster 5\n",
            " - Breakfast & Brunch, 466\n",
            " - Italian, 415\n",
            " - Sandwiches, 389\n",
            " - Japanese, 375\n",
            " - Pizza, 348\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBahZxfXVka_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8785f092-758d-49cc-9989-4f9fbe1dbbdd"
      },
      "source": [
        "labels_to_list_of_clusters(z_norm)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([   1,    2,    3,    5,    7,    9,   11,   15,   16,   21,   22,\n",
              "          23,   30,   31,   34,   35,   41,   43,   47,   51,   52,   55,\n",
              "          56,   63,   66,   73,   78,   80,   84,   87,   89,   93,   97,\n",
              "         103,  108,  110,  113,  120,  125,  129,  131,  138,  151,  158,\n",
              "         160,  168,  171,  175,  177,  179,  180,  182,  186,  190,  197,\n",
              "         198,  200,  202,  203,  210,  213,  215,  218,  219,  225,  229,\n",
              "         233,  235,  236,  241,  242,  245,  246,  247,  248,  254,  257,\n",
              "         262,  268,  272,  280,  282,  283,  289,  291,  293,  305,  307,\n",
              "         308,  312,  313,  315,  319,  321,  324,  330,  333,  334,  336,\n",
              "         343,  345,  348,  354,  355,  361,  364,  373,  377,  380,  382,\n",
              "         383,  391,  392,  394,  395,  404,  405,  408,  413,  417,  423,\n",
              "         425,  429,  432,  436,  438,  439,  450,  453,  456,  457,  461,\n",
              "         463,  465,  470,  475,  476,  480,  482,  486,  494,  496,  497,\n",
              "         501,  503,  512,  513,  516,  518,  520,  522,  526,  533,  535,\n",
              "         543,  545,  552,  553,  558,  562,  564,  565,  572,  574,  580,\n",
              "         582,  584,  587,  590,  595,  596,  601,  602,  604,  608,  609,\n",
              "         610,  612,  614,  616,  622,  630,  636,  645,  647,  648,  655,\n",
              "         656,  657,  661,  662,  663,  666,  667,  668,  676,  678,  682,\n",
              "         683,  686,  693,  695,  698,  705,  707,  709,  711,  713,  714,\n",
              "         715,  722,  723,  725,  730,  731,  732,  739,  740,  745,  753,\n",
              "         755,  757,  760,  761,  763,  766,  770,  771,  775,  787,  788,\n",
              "         793,  794,  795,  796,  802,  806,  808,  813,  814,  817,  818,\n",
              "         819,  823,  826,  828,  831,  833,  834,  840,  841,  842,  847,\n",
              "         854,  858,  861,  868,  872,  873,  877,  881,  884,  885,  887,\n",
              "         889,  893,  895,  900,  903,  905,  912,  914,  923,  924,  930,\n",
              "         931,  932,  933,  936,  940,  945,  947,  951,  952,  954,  956,\n",
              "         958,  959,  963,  966,  971,  979,  980,  981,  988,  994,  995,\n",
              "         997,  998, 1003, 1005, 1006, 1011, 1012, 1018, 1026, 1028, 1030,\n",
              "        1032, 1033, 1034, 1035, 1038, 1043, 1046, 1052, 1054, 1059, 1063,\n",
              "        1066, 1067, 1069, 1075, 1083, 1087, 1098, 1104, 1106, 1107, 1110,\n",
              "        1112, 1114, 1115, 1117, 1118, 1122, 1130, 1131, 1136, 1150, 1152,\n",
              "        1155, 1157, 1162, 1167, 1171, 1173, 1174, 1176, 1191, 1192, 1193,\n",
              "        1195, 1198, 1199, 1202, 1207, 1208, 1209, 1210, 1211, 1212, 1215,\n",
              "        1223, 1230, 1231, 1236, 1237, 1238, 1239, 1242, 1247, 1249, 1250,\n",
              "        1251, 1257, 1261, 1263, 1264, 1265, 1268, 1272, 1287, 1292, 1296,\n",
              "        1297, 1303, 1306, 1307, 1311, 1314, 1318, 1321, 1323, 1324, 1325,\n",
              "        1326, 1327, 1329, 1333, 1336, 1340, 1343, 1345, 1346, 1349, 1351,\n",
              "        1365, 1366, 1367, 1371, 1372, 1375, 1383, 1385, 1387, 1390, 1394,\n",
              "        1403, 1404, 1405, 1410, 1411, 1412, 1413, 1417, 1418, 1422, 1424,\n",
              "        1426, 1429, 1430, 1433, 1437, 1440, 1443, 1446, 1452, 1453, 1454,\n",
              "        1458, 1459, 1466, 1469, 1472, 1478, 1481, 1486, 1492, 1493, 1498,\n",
              "        1500, 1501, 1508, 1509, 1515, 1519, 1523, 1528, 1538, 1540, 1541,\n",
              "        1544, 1547, 1549, 1550, 1554, 1561, 1562, 1565, 1566, 1570, 1575,\n",
              "        1577, 1580, 1586, 1594, 1597, 1598, 1602, 1603, 1604, 1606, 1607,\n",
              "        1608, 1614, 1618, 1622, 1624, 1629, 1630, 1636, 1638, 1641, 1643,\n",
              "        1645, 1647, 1651, 1654, 1658, 1659, 1661, 1662, 1663, 1664, 1672,\n",
              "        1676, 1677, 1681, 1686, 1687, 1688, 1700, 1702, 1707, 1710, 1714,\n",
              "        1718, 1725, 1730, 1742, 1743, 1755, 1756, 1760, 1772, 1773, 1774,\n",
              "        1777, 1778, 1779, 1781, 1784, 1791, 1792, 1801, 1805, 1807, 1809,\n",
              "        1810, 1813, 1814, 1820, 1823, 1824, 1832, 1834, 1835, 1840, 1848,\n",
              "        1851, 1852, 1855, 1856, 1857, 1864, 1865, 1870, 1871, 1873, 1874,\n",
              "        1876, 1880, 1883, 1886, 1894, 1898, 1899, 1902, 1903, 1910, 1912,\n",
              "        1913, 1915, 1916, 1926, 1927, 1930, 1931, 1932, 1935, 1937, 1943,\n",
              "        1947, 1948, 1956, 1967, 1969, 1971, 1975, 1981, 1982, 1983, 1984,\n",
              "        1994, 1996, 1997, 2000, 2007, 2010, 2013, 2015, 2021, 2023, 2027,\n",
              "        2029, 2033, 2034, 2035, 2038, 2039, 2040, 2047, 2052, 2053, 2055,\n",
              "        2058, 2064, 2067, 2070, 2071, 2073, 2075, 2081, 2082, 2085, 2091,\n",
              "        2093, 2096, 2101, 2102, 2105, 2107, 2109, 2116, 2117, 2120, 2122,\n",
              "        2123, 2127, 2129, 2134, 2138, 2139, 2142, 2154, 2157, 2168, 2169,\n",
              "        2170, 2171, 2176, 2181, 2184, 2188, 2189, 2190, 2191, 2198, 2209,\n",
              "        2210, 2212, 2217, 2219, 2224, 2226, 2227, 2229, 2233, 2234, 2235,\n",
              "        2237, 2242, 2255, 2256, 2265, 2270, 2271, 2273, 2281, 2285, 2290,\n",
              "        2293, 2294, 2295, 2300, 2301, 2312, 2315, 2323, 2327, 2329, 2333,\n",
              "        2334, 2338, 2339, 2346, 2351, 2356, 2361, 2366, 2368, 2370, 2374,\n",
              "        2375, 2376, 2387, 2388, 2404, 2407, 2408, 2413, 2423, 2428, 2429,\n",
              "        2435, 2436, 2442, 2457, 2458, 2460, 2464, 2466, 2467, 2470, 2472,\n",
              "        2474, 2476, 2479, 2480, 2484, 2486, 2493, 2504, 2506, 2507, 2513,\n",
              "        2515, 2516, 2518, 2520, 2521, 2533, 2537, 2538, 2544, 2546, 2551,\n",
              "        2553, 2558, 2560, 2564, 2567, 2568, 2571, 2573, 2575, 2581, 2587,\n",
              "        2589, 2590, 2594, 2598, 2601, 2602, 2603, 2608, 2609, 2611, 2614,\n",
              "        2618, 2619, 2625, 2628, 2632, 2637, 2644, 2646, 2649, 2651, 2659,\n",
              "        2670, 2671, 2672, 2682, 2684, 2692, 2695, 2700, 2704, 2707, 2710,\n",
              "        2717, 2718, 2720, 2723, 2724, 2726, 2728, 2731, 2734, 2741, 2742,\n",
              "        2746, 2754, 2758, 2759, 2762, 2771, 2776, 2777, 2778, 2780, 2781,\n",
              "        2782, 2783, 2790, 2794, 2803, 2810, 2811, 2815, 2822, 2824, 2829,\n",
              "        2835, 2836, 2841, 2846, 2850, 2853, 2861, 2866, 2868, 2869, 2874,\n",
              "        2879, 2882, 2883, 2885, 2887, 2891, 2893, 2898, 2900, 2906, 2914,\n",
              "        2918, 2921, 2924, 2929, 2934, 2935, 2937, 2942, 2947, 2949, 2952,\n",
              "        2957, 2958, 2960, 2962, 2965, 2966, 2967, 2973, 2974, 2976, 2978,\n",
              "        2985, 2992, 2994, 2996, 2998, 3003, 3012, 3013, 3014, 3015, 3019,\n",
              "        3021, 3027, 3028, 3032, 3033, 3034, 3036, 3041, 3053, 3061, 3065,\n",
              "        3070, 3079, 3080, 3081, 3087, 3094, 3102, 3108, 3112, 3119, 3120,\n",
              "        3122, 3124, 3125, 3134, 3135, 3141, 3144, 3146, 3147, 3152, 3153,\n",
              "        3159, 3166, 3168, 3169, 3171, 3174, 3177, 3185, 3193, 3194, 3195,\n",
              "        3200, 3201, 3205, 3207, 3210, 3211, 3213, 3218, 3224, 3225, 3228,\n",
              "        3238, 3243, 3250, 3252, 3255, 3258, 3261, 3262, 3264, 3265, 3269,\n",
              "        3271, 3275, 3279, 3280, 3287, 3288, 3292, 3309, 3310, 3312, 3314,\n",
              "        3317, 3323, 3330, 3331, 3332, 3333, 3338, 3342, 3346, 3351, 3355,\n",
              "        3360, 3361, 3365, 3367, 3370, 3373, 3378, 3379, 3382]),\n",
              " array([  32,   76,   98,  117,  137,  140,  167,  181,  183,  208,  217,\n",
              "         232,  265,  274,  276,  287,  306,  311,  337,  340,  349,  353,\n",
              "         386,  401,  454,  478,  484,  502,  509,  515,  538,  591,  621,\n",
              "         637,  642,  664,  716,  778,  784,  805,  879,  894,  918,  928,\n",
              "         957,  972,  990,  992,  996, 1010, 1022, 1024, 1029, 1142, 1168,\n",
              "        1184, 1267, 1335, 1339, 1357, 1398, 1421, 1434, 1455, 1470, 1484,\n",
              "        1510, 1529, 1542, 1545, 1557, 1576, 1587, 1646, 1684, 1689, 1734,\n",
              "        1754, 1788, 1797, 1815, 1843, 1897, 1911, 1922, 1950, 1959, 1993,\n",
              "        1999, 2003, 2036, 2046, 2069, 2076, 2086, 2097, 2180, 2193, 2194,\n",
              "        2197, 2202, 2208, 2264, 2282, 2322, 2324, 2331, 2353, 2383, 2390,\n",
              "        2416, 2427, 2455, 2481, 2492, 2565, 2634, 2683, 2687, 2715, 2784,\n",
              "        2789, 2791, 2813, 2834, 2837, 2849, 2852, 2858, 2864, 2865, 2902,\n",
              "        2905, 2944, 2969, 3042, 3045, 3077, 3198, 3206, 3219, 3226, 3231,\n",
              "        3241, 3245, 3263, 3300, 3304, 3329, 3344, 3348, 3353, 3356]),\n",
              " array([   6,   10,   19,   26,   28,   42,   44,   59,   72,   83,   85,\n",
              "          90,   91,   96,   99,  102,  105,  109,  111,  114,  116,  119,\n",
              "         121,  122,  133,  139,  143,  144,  146,  149,  152,  155,  156,\n",
              "         157,  165,  178,  187,  188,  192,  194,  195,  204,  205,  207,\n",
              "         209,  214,  221,  222,  223,  226,  227,  231,  234,  243,  251,\n",
              "         261,  263,  270,  278,  281,  284,  285,  290,  300,  309,  318,\n",
              "         325,  327,  328,  332,  335,  338,  339,  341,  352,  358,  360,\n",
              "         362,  366,  368,  370,  372,  375,  378,  384,  387,  388,  390,\n",
              "         396,  398,  399,  400,  403,  407,  415,  416,  419,  421,  422,\n",
              "         426,  428,  430,  435,  443,  444,  447,  452,  464,  466,  471,\n",
              "         472,  481,  488,  490,  492,  493,  499,  500,  506,  507,  508,\n",
              "         517,  525,  530,  531,  534,  539,  540,  544,  551,  554,  561,\n",
              "         569,  571,  576,  577,  578,  579,  583,  585,  592,  594,  611,\n",
              "         613,  615,  620,  623,  624,  625,  626,  628,  629,  631,  643,\n",
              "         658,  660,  669,  672,  680,  684,  687,  689,  692,  694,  696,\n",
              "         699,  717,  720,  721,  728,  734,  737,  741,  747,  750,  751,\n",
              "         769,  777,  781,  785,  791,  792,  803,  812,  815,  820,  825,\n",
              "         827,  846,  851,  852,  856,  860,  864,  867,  874,  875,  878,\n",
              "         880,  891,  892,  899,  902,  913,  919,  921,  926,  935,  939,\n",
              "         943,  950,  960,  962,  970,  973,  977,  982,  984,  985,  987,\n",
              "        1001, 1004, 1019, 1020, 1036, 1037, 1042, 1047, 1050, 1055, 1060,\n",
              "        1065, 1068, 1072, 1077, 1078, 1079, 1080, 1081, 1084, 1086, 1092,\n",
              "        1094, 1096, 1099, 1100, 1101, 1103, 1119, 1124, 1125, 1132, 1133,\n",
              "        1138, 1140, 1146, 1148, 1151, 1153, 1156, 1159, 1160, 1164, 1169,\n",
              "        1170, 1177, 1178, 1196, 1200, 1201, 1203, 1220, 1224, 1225, 1226,\n",
              "        1227, 1228, 1229, 1240, 1244, 1245, 1248, 1255, 1262, 1269, 1271,\n",
              "        1274, 1278, 1279, 1281, 1282, 1285, 1289, 1294, 1299, 1301, 1302,\n",
              "        1304, 1312, 1313, 1315, 1330, 1331, 1337, 1338, 1341, 1344, 1347,\n",
              "        1348, 1352, 1353, 1354, 1356, 1358, 1360, 1363, 1364, 1369, 1378,\n",
              "        1380, 1386, 1388, 1397, 1399, 1400, 1402, 1406, 1407, 1409, 1414,\n",
              "        1435, 1438, 1442, 1444, 1450, 1451, 1457, 1474, 1475, 1480, 1491,\n",
              "        1496, 1497, 1499, 1503, 1504, 1511, 1512, 1513, 1518, 1520, 1521,\n",
              "        1524, 1526, 1527, 1534, 1535, 1539, 1543, 1563, 1568, 1572, 1578,\n",
              "        1581, 1589, 1590, 1592, 1593, 1596, 1599, 1610, 1613, 1616, 1617,\n",
              "        1620, 1621, 1626, 1628, 1642, 1644, 1653, 1656, 1668, 1674, 1680,\n",
              "        1682, 1691, 1692, 1695, 1697, 1698, 1701, 1711, 1712, 1713, 1715,\n",
              "        1720, 1721, 1727, 1728, 1733, 1735, 1740, 1746, 1749, 1761, 1762,\n",
              "        1763, 1764, 1765, 1767, 1768, 1783, 1785, 1787, 1793, 1794, 1796,\n",
              "        1803, 1804, 1806, 1811, 1812, 1830, 1836, 1841, 1844, 1846, 1847,\n",
              "        1849, 1850, 1858, 1859, 1860, 1861, 1866, 1867, 1872, 1878, 1885,\n",
              "        1887, 1892, 1893, 1901, 1918, 1921, 1924, 1928, 1934, 1942, 1945,\n",
              "        1952, 1954, 1963, 1966, 1968, 1976, 1985, 1986, 1989, 1990, 1992,\n",
              "        1998, 2002, 2004, 2005, 2008, 2009, 2017, 2019, 2022, 2026, 2037,\n",
              "        2050, 2051, 2057, 2059, 2062, 2077, 2079, 2090, 2092, 2094, 2095,\n",
              "        2100, 2104, 2108, 2110, 2112, 2114, 2119, 2124, 2132, 2133, 2137,\n",
              "        2148, 2149, 2151, 2152, 2153, 2156, 2159, 2161, 2162, 2167, 2185,\n",
              "        2192, 2201, 2207, 2215, 2216, 2222, 2225, 2230, 2231, 2240, 2245,\n",
              "        2246, 2247, 2251, 2258, 2263, 2266, 2268, 2275, 2283, 2287, 2298,\n",
              "        2303, 2304, 2305, 2307, 2309, 2310, 2316, 2318, 2320, 2328, 2335,\n",
              "        2343, 2345, 2350, 2354, 2360, 2371, 2373, 2380, 2392, 2393, 2395,\n",
              "        2397, 2400, 2403, 2406, 2409, 2417, 2418, 2424, 2426, 2430, 2437,\n",
              "        2438, 2441, 2447, 2450, 2451, 2453, 2454, 2456, 2463, 2473, 2475,\n",
              "        2483, 2487, 2488, 2489, 2495, 2498, 2499, 2501, 2503, 2510, 2517,\n",
              "        2523, 2527, 2528, 2530, 2539, 2547, 2548, 2555, 2556, 2562, 2566,\n",
              "        2569, 2572, 2576, 2578, 2580, 2586, 2592, 2595, 2597, 2607, 2610,\n",
              "        2615, 2621, 2623, 2627, 2630, 2631, 2636, 2639, 2640, 2647, 2653,\n",
              "        2655, 2660, 2665, 2666, 2667, 2668, 2673, 2675, 2676, 2677, 2680,\n",
              "        2685, 2688, 2689, 2693, 2696, 2701, 2703, 2705, 2706, 2711, 2712,\n",
              "        2716, 2719, 2725, 2733, 2735, 2736, 2738, 2739, 2743, 2744, 2748,\n",
              "        2750, 2752, 2757, 2761, 2763, 2767, 2770, 2773, 2775, 2792, 2797,\n",
              "        2798, 2799, 2802, 2804, 2805, 2806, 2807, 2812, 2814, 2817, 2818,\n",
              "        2819, 2821, 2833, 2838, 2842, 2843, 2845, 2856, 2862, 2870, 2872,\n",
              "        2877, 2878, 2886, 2888, 2890, 2894, 2901, 2907, 2910, 2911, 2916,\n",
              "        2922, 2927, 2930, 2933, 2936, 2938, 2939, 2940, 2941, 2945, 2950,\n",
              "        2955, 2956, 2959, 2970, 2972, 2979, 2981, 2982, 2988, 2990, 2993,\n",
              "        2999, 3004, 3011, 3018, 3020, 3025, 3026, 3038, 3040, 3044, 3052,\n",
              "        3055, 3056, 3057, 3059, 3064, 3066, 3068, 3073, 3074, 3078, 3083,\n",
              "        3086, 3092, 3096, 3103, 3104, 3107, 3116, 3117, 3118, 3127, 3128,\n",
              "        3136, 3137, 3138, 3139, 3140, 3142, 3145, 3148, 3150, 3154, 3155,\n",
              "        3156, 3161, 3162, 3167, 3173, 3187, 3190, 3191, 3209, 3212, 3215,\n",
              "        3230, 3232, 3234, 3235, 3242, 3244, 3246, 3249, 3253, 3266, 3268,\n",
              "        3272, 3283, 3299, 3301, 3302, 3305, 3306, 3318, 3324, 3325, 3328,\n",
              "        3337, 3340, 3341, 3343, 3347, 3349, 3350, 3352, 3354, 3359, 3362,\n",
              "        3368, 3375]),\n",
              " array([  12,   24,   25,   40,   48,   61,   88,   92,   94,   95,  104,\n",
              "         132,  135,  147,  153,  162,  164,  166,  172,  185,  191,  212,\n",
              "         239,  264,  267,  271,  273,  275,  295,  301,  304,  310,  322,\n",
              "         344,  347,  357,  365,  367,  374,  434,  440,  445,  458,  462,\n",
              "         479,  483,  491,  528,  529,  559,  575,  588,  589,  598,  600,\n",
              "         607,  641,  650,  651,  659,  670,  681,  702,  703,  718,  738,\n",
              "         748,  782,  809,  811,  829,  832,  836,  838,  843,  848,  853,\n",
              "         862,  869,  871,  886,  906,  908,  909,  934,  941,  949,  955,\n",
              "         961,  983,  989, 1002, 1008, 1009, 1015, 1017, 1023, 1039, 1053,\n",
              "        1070, 1074, 1076, 1082, 1089, 1090, 1093, 1095, 1126, 1137, 1141,\n",
              "        1144, 1147, 1149, 1154, 1165, 1166, 1179, 1180, 1188, 1218, 1233,\n",
              "        1243, 1253, 1259, 1275, 1288, 1300, 1309, 1316, 1319, 1320, 1328,\n",
              "        1370, 1392, 1401, 1427, 1436, 1445, 1448, 1449, 1460, 1463, 1468,\n",
              "        1487, 1506, 1516, 1525, 1532, 1537, 1546, 1567, 1569, 1585, 1591,\n",
              "        1595, 1601, 1631, 1632, 1649, 1652, 1666, 1670, 1679, 1690, 1696,\n",
              "        1705, 1722, 1723, 1731, 1737, 1752, 1757, 1759, 1776, 1782, 1799,\n",
              "        1800, 1831, 1853, 1869, 1896, 1917, 1929, 1946, 1949, 1955, 1957,\n",
              "        1970, 1974, 1987, 1988, 2018, 2031, 2032, 2049, 2061, 2080, 2084,\n",
              "        2103, 2113, 2115, 2118, 2126, 2128, 2145, 2150, 2155, 2164, 2173,\n",
              "        2174, 2186, 2199, 2204, 2205, 2214, 2221, 2236, 2238, 2248, 2261,\n",
              "        2276, 2278, 2279, 2284, 2288, 2292, 2313, 2314, 2317, 2330, 2332,\n",
              "        2340, 2341, 2349, 2352, 2378, 2382, 2389, 2391, 2394, 2399, 2401,\n",
              "        2402, 2410, 2432, 2434, 2439, 2443, 2448, 2465, 2502, 2519, 2550,\n",
              "        2557, 2582, 2596, 2624, 2648, 2654, 2658, 2661, 2662, 2663, 2669,\n",
              "        2679, 2681, 2686, 2702, 2721, 2722, 2729, 2730, 2732, 2760, 2772,\n",
              "        2785, 2793, 2820, 2830, 2840, 2860, 2873, 2904, 2912, 2920, 2923,\n",
              "        2943, 2953, 2961, 2968, 2987, 3022, 3035, 3075, 3097, 3098, 3099,\n",
              "        3110, 3114, 3133, 3182, 3204, 3274, 3289, 3290, 3296, 3308, 3334,\n",
              "        3335, 3380]),\n",
              " array([   4,    8,   17,   18,   29,   33,   37,   38,   39,   45,   46,\n",
              "          50,   54,   57,   60,   62,   65,   67,   71,   74,   75,   81,\n",
              "          82,   86,  100,  101,  115,  118,  124,  127,  128,  134,  141,\n",
              "         142,  148,  150,  154,  161,  163,  169,  170,  184,  199,  201,\n",
              "         206,  216,  220,  224,  228,  230,  237,  249,  250,  252,  255,\n",
              "         277,  286,  292,  294,  299,  302,  314,  316,  317,  320,  323,\n",
              "         331,  342,  346,  359,  363,  379,  381,  393,  406,  409,  411,\n",
              "         418,  424,  431,  437,  446,  448,  449,  459,  460,  467,  468,\n",
              "         473,  489,  504,  505,  514,  519,  523,  524,  527,  532,  536,\n",
              "         537,  547,  560,  563,  567,  573,  586,  593,  597,  617,  619,\n",
              "         634,  652,  665,  673,  675,  691,  700,  701,  704,  706,  712,\n",
              "         727,  729,  735,  742,  744,  749,  754,  758,  764,  768,  772,\n",
              "         774,  779,  786,  799,  800,  801,  810,  821,  822,  824,  830,\n",
              "         835,  837,  839,  845,  849,  850,  859,  863,  865,  888,  890,\n",
              "         904,  910,  916,  917,  927,  929,  937,  942,  946,  948,  964,\n",
              "         967,  969,  974,  975,  976,  978,  986,  993, 1016, 1021, 1027,\n",
              "        1040, 1041, 1057, 1061, 1062, 1064, 1071, 1091, 1097, 1116, 1123,\n",
              "        1127, 1135, 1139, 1161, 1163, 1172, 1181, 1182, 1183, 1187, 1189,\n",
              "        1190, 1194, 1204, 1216, 1221, 1234, 1241, 1254, 1258, 1266, 1270,\n",
              "        1273, 1276, 1277, 1283, 1284, 1286, 1293, 1298, 1305, 1308, 1317,\n",
              "        1334, 1342, 1350, 1359, 1361, 1368, 1376, 1377, 1379, 1382, 1384,\n",
              "        1395, 1408, 1416, 1419, 1420, 1428, 1431, 1456, 1461, 1462, 1464,\n",
              "        1476, 1483, 1488, 1490, 1495, 1505, 1507, 1522, 1530, 1531, 1533,\n",
              "        1536, 1548, 1553, 1558, 1559, 1560, 1571, 1573, 1583, 1584, 1600,\n",
              "        1605, 1619, 1625, 1633, 1634, 1637, 1640, 1655, 1660, 1665, 1667,\n",
              "        1669, 1675, 1683, 1694, 1704, 1708, 1709, 1716, 1719, 1724, 1726,\n",
              "        1732, 1736, 1738, 1739, 1741, 1747, 1750, 1751, 1753, 1758, 1769,\n",
              "        1771, 1775, 1780, 1786, 1795, 1798, 1802, 1816, 1818, 1822, 1825,\n",
              "        1827, 1829, 1837, 1842, 1845, 1862, 1863, 1879, 1881, 1884, 1895,\n",
              "        1904, 1906, 1909, 1920, 1923, 1933, 1936, 1941, 1951, 1958, 1962,\n",
              "        1972, 1977, 1978, 1980, 1991, 2006, 2012, 2014, 2016, 2020, 2024,\n",
              "        2028, 2042, 2045, 2054, 2066, 2074, 2078, 2083, 2087, 2088, 2098,\n",
              "        2111, 2121, 2130, 2131, 2140, 2143, 2160, 2165, 2175, 2187, 2195,\n",
              "        2196, 2203, 2206, 2211, 2223, 2228, 2243, 2249, 2250, 2252, 2253,\n",
              "        2257, 2259, 2260, 2262, 2269, 2272, 2277, 2286, 2289, 2291, 2296,\n",
              "        2299, 2302, 2311, 2319, 2321, 2344, 2348, 2355, 2357, 2358, 2359,\n",
              "        2362, 2363, 2367, 2369, 2372, 2379, 2396, 2398, 2405, 2420, 2425,\n",
              "        2431, 2433, 2440, 2444, 2459, 2461, 2468, 2469, 2477, 2485, 2490,\n",
              "        2496, 2500, 2508, 2512, 2524, 2525, 2526, 2531, 2532, 2534, 2536,\n",
              "        2541, 2542, 2543, 2545, 2549, 2561, 2563, 2570, 2574, 2577, 2583,\n",
              "        2584, 2585, 2588, 2591, 2593, 2599, 2604, 2617, 2622, 2633, 2638,\n",
              "        2641, 2642, 2650, 2652, 2656, 2657, 2664, 2674, 2678, 2697, 2698,\n",
              "        2709, 2714, 2737, 2740, 2749, 2751, 2753, 2756, 2765, 2766, 2779,\n",
              "        2787, 2788, 2795, 2800, 2808, 2809, 2816, 2826, 2828, 2832, 2844,\n",
              "        2851, 2854, 2871, 2875, 2881, 2889, 2892, 2897, 2899, 2909, 2915,\n",
              "        2925, 2926, 2928, 2932, 2948, 2951, 2954, 2963, 2971, 2977, 2980,\n",
              "        2995, 3005, 3006, 3008, 3010, 3016, 3023, 3024, 3030, 3031, 3037,\n",
              "        3039, 3048, 3049, 3050, 3062, 3063, 3069, 3076, 3085, 3088, 3089,\n",
              "        3090, 3091, 3100, 3101, 3105, 3111, 3121, 3129, 3151, 3165, 3170,\n",
              "        3172, 3176, 3180, 3181, 3183, 3196, 3197, 3199, 3202, 3220, 3222,\n",
              "        3223, 3229, 3233, 3236, 3237, 3239, 3240, 3248, 3254, 3257, 3259,\n",
              "        3260, 3267, 3276, 3277, 3278, 3282, 3285, 3286, 3293, 3295, 3303,\n",
              "        3307, 3320, 3322, 3327, 3339, 3345, 3363, 3364, 3369, 3377, 3381]),\n",
              " array([   0,   13,   14,   20,   27,   36,   49,   53,   58,   64,   68,\n",
              "          69,   70,   77,   79,  106,  107,  112,  123,  126,  130,  136,\n",
              "         145,  159,  173,  174,  176,  189,  193,  196,  211,  238,  240,\n",
              "         244,  253,  256,  258,  259,  260,  266,  269,  279,  288,  296,\n",
              "         297,  298,  303,  326,  329,  350,  351,  356,  369,  371,  376,\n",
              "         385,  389,  397,  402,  410,  412,  414,  420,  427,  433,  441,\n",
              "         442,  451,  455,  469,  474,  477,  485,  487,  495,  498,  510,\n",
              "         511,  521,  541,  542,  546,  548,  549,  550,  555,  556,  557,\n",
              "         566,  568,  570,  581,  599,  603,  605,  606,  618,  627,  632,\n",
              "         633,  635,  638,  639,  640,  644,  646,  649,  653,  654,  671,\n",
              "         674,  677,  679,  685,  688,  690,  697,  708,  710,  719,  724,\n",
              "         726,  733,  736,  743,  746,  752,  756,  759,  762,  765,  767,\n",
              "         773,  776,  780,  783,  789,  790,  797,  798,  804,  807,  816,\n",
              "         844,  855,  857,  866,  870,  876,  882,  883,  896,  897,  898,\n",
              "         901,  907,  911,  915,  920,  922,  925,  938,  944,  953,  965,\n",
              "         968,  991,  999, 1000, 1007, 1013, 1014, 1025, 1031, 1044, 1045,\n",
              "        1048, 1049, 1051, 1056, 1058, 1073, 1085, 1088, 1102, 1105, 1108,\n",
              "        1109, 1111, 1113, 1120, 1121, 1128, 1129, 1134, 1143, 1145, 1158,\n",
              "        1175, 1185, 1186, 1197, 1205, 1206, 1213, 1214, 1217, 1219, 1222,\n",
              "        1232, 1235, 1246, 1252, 1256, 1260, 1280, 1290, 1291, 1295, 1310,\n",
              "        1322, 1332, 1355, 1362, 1373, 1374, 1381, 1389, 1391, 1393, 1396,\n",
              "        1415, 1423, 1425, 1432, 1439, 1441, 1447, 1465, 1467, 1471, 1473,\n",
              "        1477, 1479, 1482, 1485, 1489, 1494, 1502, 1514, 1517, 1551, 1552,\n",
              "        1555, 1556, 1564, 1574, 1579, 1582, 1588, 1609, 1611, 1612, 1615,\n",
              "        1623, 1627, 1635, 1639, 1648, 1650, 1657, 1671, 1673, 1678, 1685,\n",
              "        1693, 1699, 1703, 1706, 1717, 1729, 1744, 1745, 1748, 1766, 1770,\n",
              "        1789, 1790, 1808, 1817, 1819, 1821, 1826, 1828, 1833, 1838, 1839,\n",
              "        1854, 1868, 1875, 1877, 1882, 1888, 1889, 1890, 1891, 1900, 1905,\n",
              "        1907, 1908, 1914, 1919, 1925, 1938, 1939, 1940, 1944, 1953, 1960,\n",
              "        1961, 1964, 1965, 1973, 1979, 1995, 2001, 2011, 2025, 2030, 2041,\n",
              "        2043, 2044, 2048, 2056, 2060, 2063, 2065, 2068, 2072, 2089, 2099,\n",
              "        2106, 2125, 2135, 2136, 2141, 2144, 2146, 2147, 2158, 2163, 2166,\n",
              "        2172, 2177, 2178, 2179, 2182, 2183, 2200, 2213, 2218, 2220, 2232,\n",
              "        2239, 2241, 2244, 2254, 2267, 2274, 2280, 2297, 2306, 2308, 2325,\n",
              "        2326, 2336, 2337, 2342, 2347, 2364, 2365, 2377, 2381, 2384, 2385,\n",
              "        2386, 2411, 2412, 2414, 2415, 2419, 2421, 2422, 2445, 2446, 2449,\n",
              "        2452, 2462, 2471, 2478, 2482, 2491, 2494, 2497, 2505, 2509, 2511,\n",
              "        2514, 2522, 2529, 2535, 2540, 2552, 2554, 2559, 2579, 2600, 2605,\n",
              "        2606, 2612, 2613, 2616, 2620, 2626, 2629, 2635, 2643, 2645, 2690,\n",
              "        2691, 2694, 2699, 2708, 2713, 2727, 2745, 2747, 2755, 2764, 2768,\n",
              "        2769, 2774, 2786, 2796, 2801, 2823, 2825, 2827, 2831, 2839, 2847,\n",
              "        2848, 2855, 2857, 2859, 2863, 2867, 2876, 2880, 2884, 2895, 2896,\n",
              "        2903, 2908, 2913, 2917, 2919, 2931, 2946, 2964, 2975, 2983, 2984,\n",
              "        2986, 2989, 2991, 2997, 3000, 3001, 3002, 3007, 3009, 3017, 3029,\n",
              "        3043, 3046, 3047, 3051, 3054, 3058, 3060, 3067, 3071, 3072, 3082,\n",
              "        3084, 3093, 3095, 3106, 3109, 3113, 3115, 3123, 3126, 3130, 3131,\n",
              "        3132, 3143, 3149, 3157, 3158, 3160, 3163, 3164, 3175, 3178, 3179,\n",
              "        3184, 3186, 3188, 3189, 3192, 3203, 3208, 3214, 3216, 3217, 3221,\n",
              "        3227, 3247, 3251, 3256, 3270, 3273, 3281, 3284, 3291, 3294, 3297,\n",
              "        3298, 3311, 3313, 3315, 3316, 3319, 3321, 3326, 3336, 3357, 3358,\n",
              "        3366, 3371, 3372, 3374, 3376, 3383])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    }
  ]
}